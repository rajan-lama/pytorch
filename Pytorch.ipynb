{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dozEiKviHrV6",
        "outputId": "35e414d5-5bd6-44b2-afa4-8d48c253e688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print( torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "# print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3axarOeFIPHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Tensor CPU Example**"
      ],
      "metadata": {
        "id": "Q7NZ4PB-IxGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "first_tensor = torch.tensor([[1,2,3,9],[4,5,6,7]])\n",
        "second_tensor = torch.tensor([[11,21,13,91],[14,51,61,71]])\n",
        "print(first_tensor)\n",
        "print(second_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_l6t5wPI3Sj",
        "outputId": "4d124930-bdd4-475e-a59a-35f2ac8360a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 9],\n",
            "        [4, 5, 6, 7]])\n",
            "tensor([[11, 21, 13, 91],\n",
            "        [14, 51, 61, 71]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "add_tensor = first_tensor + second_tensor\n",
        "print(add_tensor)\n",
        "print(add_tensor.size())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY3xkVDDJPz1",
        "outputId": "1bb9b787-6450-41b0-9633-0e80b8be84ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 12,  23,  16, 100],\n",
            "        [ 18,  56,  67,  78]])\n",
            "torch.Size([2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sub_tensor = first_tensor - second_tensor\n",
        "print(sub_tensor)\n",
        "print(sub_tensor.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoYRLNLHJ3vj",
        "outputId": "5d5e1d27-78e6-44df-d9b3-185e0981cec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-10, -19, -10, -82],\n",
            "        [-10, -46, -55, -64]])\n",
            "torch.Size([2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8oS-ZyE6J7GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Tensors GPU Example**"
      ],
      "metadata": {
        "id": "Nma5z5VUJ9-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print( torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALnsyaLiKDVj",
        "outputId": "bb89f8a8-f196-4db4-9306-07214c211a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xYLY87iKIoi",
        "outputId": "648f089a-0f83-4ee6-db20-2626b8f5af3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_tensor = torch.tensor([[1,2,3,9],[4,5,6,7]], device=device)\n",
        "second_tensor = torch.tensor([[11,21,13,91],[14,51,61,71]], device=device)\n",
        "\n",
        "multi_tensor = first_tensor * second_tensor\n",
        "print(multi_tensor)\n",
        "print(multi_tensor.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCramPEmKR5_",
        "outputId": "429bafbb-bf1d-4a17-8707-00a9a5fe454c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 11,  42,  39, 819],\n",
            "        [ 56, 255, 366, 497]])\n",
            "torch.Size([2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Moving Tensors from CPU to GPU**"
      ],
      "metadata": {
        "id": "uIlCqDUhQBn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1st way\n",
        "Tensor.cuda()\n",
        "\n",
        "#2nd Way\n",
        "Tensor = Tensor.to(\"cuda\")\n",
        "\n",
        "#3rd way\n",
        "Tensor.to(\"cuda:0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "zyHoGQ0_Krse",
        "outputId": "dd432689-069e-4aaf-e98b-f789a76d1f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tensor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-074f92fa0a95>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#1st way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#2nd Way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Moving Tensors from GPU to CPU**"
      ],
      "metadata": {
        "id": "5XVHnuUeQeSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st case Ten sor with required_grad = false\n",
        "Tensor.cpu()\n",
        "\n",
        "# 2nd case Tensor with required_grad = True\n",
        "Tensor.detach().cpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "s_XNpL5vQsaP",
        "outputId": "78ca8f5d-0cf5-4d66-c9bf-5ad1956b60d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Tensor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6a83b2392559>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1st case Ten sor with required_grad = false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 2nd case Tensor with required_grad = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Tensor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Different ways to create tensors**"
      ],
      "metadata": {
        "id": "HzqGUIQDQr16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "P84OlEOQQmJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize a tensor from a python list\n",
        "tensor_from_list = torch.tensor([1,2,3,4,5])\n",
        "print(tensor_from_list)\n",
        "\n",
        "# initialize a tensor from a tuple\n",
        "tensor_from_tuple = torch.tensor((1,2,3,4,5))\n",
        "print(tensor_from_tuple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHLZa_3ZTCYt",
        "outputId": "0a3aca0a-218b-4817-c9b7-699d9317d03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5])\n",
            "tensor([1, 2, 3, 4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize a tensor from a np.array\n",
        "tensor_from_array = torch.tensor(np.array([1,2,3,4,5]))\n",
        "print(\"Tensor from array\", tensor_from_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf1emhksTYfJ",
        "outputId": "bf6b8658-d874-4ad7-e6df-53fc36a9e135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor from array tensor([1, 2, 3, 4, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Different functions for creating tensors\n",
        "\n",
        "# torch.empty(), torch.ones(), torch.zeros()\n",
        "\n",
        "tensor_empty = torch.empty(2,3)\n",
        "print(tensor_empty)\n",
        "\n",
        "tensor_ones = torch.ones(2,3)\n",
        "print(tensor_ones)\n",
        "\n",
        "tensor_zeros = torch.zeros(2,3)\n",
        "print(tensor_zeros)\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY_-f1nSTpQ5",
        "outputId": "9d140034-c27e-411d-998a-adc7a853dfd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6.8244e-07, 1.4580e-19, 4.5450e+30],\n",
            "        [1.8524e+28, 2.1715e-18, 2.4283e-18]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # tensors initialized  by size with random values\n",
        "# returns a tensor filled with random numbers from a uniform distribution\n",
        "\n",
        "tensor_rand_un = torch.rand(4,5)\n",
        "print(tensor_rand_un)\n",
        "\n",
        "# returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1\n",
        "tensor_rand_no = torch.randn(4,5)\n",
        "print(tensor_rand_no)\n",
        "\n",
        "# returns a tensor filled with random integers generates uniformly\n",
        "tensor_rand_in = torch.randint(0,10,(4,5))\n",
        "print(tensor_rand_in)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok7BPe9wWjoU",
        "outputId": "f271e76f-94f3-4fb6-a978-33c1b1d41fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5324, 0.1589, 0.1971, 0.4694, 0.6109],\n",
            "        [0.5883, 0.2102, 0.0138, 0.2320, 0.4963],\n",
            "        [0.7478, 0.4539, 0.7635, 0.3206, 0.6523],\n",
            "        [0.6996, 0.6566, 0.3642, 0.6851, 0.9621]])\n",
            "tensor([[-0.3053, -1.4811, -0.2722,  0.7684, -1.6076],\n",
            "        [ 1.0996,  1.0618,  1.0975,  1.5158, -1.0690],\n",
            "        [-2.0803,  0.2616,  0.8359, -0.0914, -0.1082],\n",
            "        [-1.3977, -1.4364,  0.0650, -1.5926, -0.2657]])\n",
            "tensor([[7, 0, 6, 9, 5],\n",
            "        [1, 5, 1, 6, 0],\n",
            "        [7, 3, 0, 4, 9],\n",
            "        [5, 9, 3, 4, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize a tensor of ones\n",
        "tensor_ones = torch.ones_like(tensor_rand_in)\n",
        "print(tensor_ones)\n",
        "\n",
        "# initialize a tensor of zeros\n",
        "tensor_zeros = torch.zeros_like(tensor_ones)\n",
        "print(tensor_zeros)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01l5XxDHYIID",
        "outputId": "cb6fec9c-97c8-4f50-a681-8ee3f4296036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1]])\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Attributes**\n",
        "\n",
        "Knowing device location, datatype, dimnetion, adn rank is very important"
      ],
      "metadata": {
        "id": "bgOYvTWXYxJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_tensor = torch.tensor([[1,2,3,9],[4,5,6,7]])\n",
        "second_tensor = torch.tensor([[11,21,13,91],[14,51,61,71]])"
      ],
      "metadata": {
        "id": "U-rh4X71Yw9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.device indicates the tensor's device location"
      ],
      "metadata": {
        "id": "hFEuLy5qZNhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeihHcVRYlja",
        "outputId": "e6047b3c-c15e-4080-e61d-493dbbecceae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.dtype indicates the tensor's data type"
      ],
      "metadata": {
        "id": "AqCQVZ01ZWD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYpvWPAuZVzx",
        "outputId": "b8e26b23-af21-4ac4-e4da-d85c8be55c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.shape shows the tensors dimentions"
      ],
      "metadata": {
        "id": "YLkYLVaaZWb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlYUOVRdZVVz",
        "outputId": "5e87e97e-afeb-4400-a067-45f6e049b703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.ndim identifies the number of a tensor's dimentions or rank"
      ],
      "metadata": {
        "id": "2Z_tnIKZZz63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6TiOBZDaS0A",
        "outputId": "76e8a159-29d8-49a1-84a5-2cafd7e53891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_tensor = torch.tensor([[11,21,13,91],[14,51,61,71]], dtype=torch.float32)\n",
        "second_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ANssh7aVAa",
        "outputId": "d6487b9f-a0d8-459c-ffa8-6a53271023a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Data Types**"
      ],
      "metadata": {
        "id": "Ya6Ei4kBaxTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Integer data type tensor\n",
        "int_tensor=torch.tensor([[1,2,3,9],[4,5,6,7]], dtype=torch.int8)\n",
        "print(int_tensor)\n",
        "print(int_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc5GyVVsacdz",
        "outputId": "d70f00ef-74b2-4abd-beff-c670c0510539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 9],\n",
            "        [4, 5, 6, 7]], dtype=torch.int8)\n",
            "torch.int8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Float data type\n",
        "float_tensor=torch.tensor([[1,2,3,9],[4,5,6,7]], dtype=torch.float16)\n",
        "print(float_tensor)\n",
        "print(float_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61sKc51Dawy1",
        "outputId": "0b743ea8-1266-469d-915b-8628bcdb44de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3., 9.],\n",
            "        [4., 5., 6., 7.]], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# short data tyoe tensor\n",
        "short_tensor=torch.tensor([[1,2,3,9],[4,5,6,7]], dtype=torch.short)\n",
        "print(short_tensor)\n",
        "print(short_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebFAttXCbSzX",
        "outputId": "fb2654ac-dc86-449c-8cbd-57fb4ba7f813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 9],\n",
            "        [4, 5, 6, 7]], dtype=torch.int16)\n",
            "torch.int16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# casting a tensor to a new data type (1nd way)\n",
        "first_tensor=int_tensor.float()\n",
        "print(first_tensor)\n",
        "print(first_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6bMEJAMbrJP",
        "outputId": "3cc1ca0c-7a68-42f6-f628-cc5b0c88ec2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3., 9.],\n",
            "        [4., 5., 6., 7.]])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# casting a tensor to a new data type (2st way)\n",
        "sec_tensor=int_tensor.type(torch.float16)\n",
        "print(sec_tensor)\n",
        "print(sec_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh_5eG3ebcYq",
        "outputId": "54ccbac4-20c2-419c-ed61-4f9f0938856e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3., 9.],\n",
            "        [4., 5., 6., 7.]], dtype=torch.float16)\n",
            "torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Tesnsors from random samples**"
      ],
      "metadata": {
        "id": "s41Lq9UUcKAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title torch.rand() selects random values from a uniform distribution on the interval [0-1]\n",
        "# torch.rand() selects random values from a standard normal distribution\n",
        "\n",
        "torch.manual_seed(111) # this will make generator generate same data every time\n",
        "torch.rand(2,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN8tBYY9Cg9e",
        "outputId": "34c8bf84-7637-4fec-8b81-dbb3120b7966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7156, 0.9140, 0.2819],\n",
              "        [0.2581, 0.6311, 0.6001]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title torch.randint() selects integers generated uniformly between specified low and high values\n",
        "\n",
        "torch.randint(0,10,(2,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVTUmrgsC4wI",
        "outputId": "57903074-8ace-4297-b2aa-c09fe25fbf19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 6, 4],\n",
              "        [4, 4, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create tensors like other tensors**"
      ],
      "metadata": {
        "id": "mSDOKHc2EgmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create a tensor of shape (2,5) filled with ones\n",
        "starting_tensors = torch.zeros(2,5)\n",
        "print(starting_tensors)\n",
        "print(starting_tensors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvcyYg2wEmFn",
        "outputId": "07702713-c6cd-465c-84d2-778ec4257888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "torch.Size([2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Tensor with the same size filled with random numbers\n",
        "torch.manual_seed(111)\n",
        "random_tensors = torch.rand_like(starting_tensors)\n",
        "print(random_tensors)\n",
        "print(random_tensors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HG4kwRdFL8j",
        "outputId": "3b335b58-078f-48ae-94b2-4457ebd7c92d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7156, 0.9140, 0.2819, 0.2581, 0.6311],\n",
            "        [0.6001, 0.9312, 0.2153, 0.6033, 0.7328]])\n",
            "torch.Size([2, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create a tensor with the same shape filled with ones\n",
        "torch.ones_like(starting_tensors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjRqy82XFaU6",
        "outputId": "16f81230-0931-48e9-b282-af34ce96cafa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create a tensor with the same shape filled with provided values\n",
        "torch.full_like(starting_tensors, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gygRK9HrFt_g",
        "outputId": "d65de38a-fdce-4ddf-95c4-d8116e82d84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 5., 5., 5., 5.],\n",
              "        [5., 5., 5., 5., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor operator**"
      ],
      "metadata": {
        "id": "UW57bdLKElcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Indexing 1 dim tensor example\n",
        "\n",
        "one_dim_tensor = torch.tensor([1,2,3,4,5])\n",
        "print(one_dim_tensor)\n",
        "print(one_dim_tensor[1])\n",
        "print(one_dim_tensor[2])\n",
        "print(one_dim_tensor[2].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcfKj219DXMo",
        "outputId": "3d87a47b-5064-413d-9db4-e8a009d8e92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5])\n",
            "tensor(2)\n",
            "tensor(3)\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Slicing 1 dim tensor example\n",
        "\n",
        "# [start:end:step]\n",
        "\n",
        "one_dim_tensor = torch.tensor([1,2,3,4,5])\n",
        "print(one_dim_tensor)\n",
        "print(one_dim_tensor[1:3])\n",
        "print(one_dim_tensor[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzaujUMtXTBz",
        "outputId": "090b3f1a-ddd2-4d5d-9fc4-ff2b7c59e810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5])\n",
            "tensor([2, 3])\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Indexing 2 dim tensor example\n",
        "two_dim_tensor = torch.tensor([[1,2,3,4,5],[6,7,8,9,10],[16,17,18,19,30],[26,27,28,29,20]])\n",
        "\n",
        "print(two_dim_tensor[1][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9BS6sAxXaxo",
        "outputId": "5f38c8ff-c921-43c1-870c-04b888e6380c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Slicing 2 dim tensor example\n",
        "\n",
        "two_dim_tensor = torch.tensor([[1,2,3,4,5],[6,7,8,9,10],[16,17,18,19,30],[26,27,28,29,20]])\n",
        "print(\"First three element of first row: \", two_dim_tensor[0, 2:4])\n",
        "print(\"First four element of Second row: \", two_dim_tensor[1, 2:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRNYLEB5Y_Zt",
        "outputId": "021ee5ae-1554-437e-e56d-30c2c324623a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First three element of first row:  tensor([3, 4])\n",
            "First four element of Second row:  tensor([8, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title use Indexing to extract data that meets some criteria\n",
        "two_dim_tensor = torch.tensor([[1,2,3,4,5],[6,7,8,9,10],[16,17,18,19,30],[26,27,28,29,20]])\n",
        "two_dim_tensor[two_dim_tensor<11]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDDos2ccZ6LE",
        "outputId": "d6572db1-8b89-4db9-fb41-b274ae6a0a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title combining tensor\n",
        "\n",
        "\n",
        "three_dim_tensor =  torch.stack((two_dim_tensor, two_dim_tensor));\n",
        "\n",
        "print( three_dim_tensor )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTpKVXoCasCu",
        "outputId": "0e3e556d-a7cb-47ce-f22c-680d870291db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1,  2,  3,  4,  5],\n",
            "         [ 6,  7,  8,  9, 10],\n",
            "         [16, 17, 18, 19, 30],\n",
            "         [26, 27, 28, 29, 20]],\n",
            "\n",
            "        [[ 1,  2,  3,  4,  5],\n",
            "         [ 6,  7,  8,  9, 10],\n",
            "         [16, 17, 18, 19, 30],\n",
            "         [26, 27, 28, 29, 20]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Splitting tensors\n",
        "\n",
        "first_tensor, second_tensor = torch.split(three_dim_tensor, 1, dim=0)\n",
        "\n",
        "print(first_tensor)\n",
        "print(second_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbdgTsIXaxIb",
        "outputId": "386b4deb-fb56-40ff-ecce-63b8e01a1501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1,  2,  3,  4,  5],\n",
            "         [ 6,  7,  8,  9, 10],\n",
            "         [16, 17, 18, 19, 30],\n",
            "         [26, 27, 28, 29, 20]]])\n",
            "tensor([[[ 1,  2,  3,  4,  5],\n",
            "         [ 6,  7,  8,  9, 10],\n",
            "         [16, 17, 18, 19, 30],\n",
            "         [26, 27, 28, 29, 20]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Splitting 2 - DIM tensors\n",
        "torch.unbind(two_dim_tensor, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcNN9foqazXR",
        "outputId": "3dc42576-63c3-45f4-fe4b-e3d583855245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1,  6, 16, 26]),\n",
              " tensor([ 2,  7, 17, 27]),\n",
              " tensor([ 3,  8, 18, 28]),\n",
              " tensor([ 4,  9, 19, 29]),\n",
              " tensor([ 5, 10, 30, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pointwise Operations / math functions\n",
        "\n",
        "# basic math functions:  add(), mul(), div(), neg(), and true_divide()\n",
        "\n",
        "# Functions for truncation:  ceil(), clamp(), floor(), etc.\n",
        "\n",
        "# logical functions\n",
        "\n",
        "a = torch.tensor([10,2,8,6,4])\n",
        "b = torch.tensor([1,2,3,2,1])\n",
        "\n",
        "print('adding tensors a and b: ', a.add(b))\n",
        "print('multiplying tensors a and b: ', a.mul(b))\n",
        "print('dividing tensors a and b: ', a.div(b))\n",
        "print('subtracting tensors a and b: ', a.sub(b))"
      ],
      "metadata": {
        "id": "p9CC3R0HzQzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Reduction Operations\n",
        "\n",
        "# Results in reducing the dimentionality or rank of the tensor\n",
        "\n",
        "# includes statistical functions such as mean, median, mode etc."
      ],
      "metadata": {
        "id": "hd9yQ2Qczsq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Comparison Operations\n",
        "\n",
        "# Compare all the values within a tensor or compare values of two different tensors\n",
        "\n",
        "# Functions to find the minimum or maximum value, sort tensor values, test tensor status or condition, and similar\n",
        "\n",
        "c = torch.tensor([[20.,14.,11.,8.], [3., 12., 24., 12.]])\n",
        "print(c.max())\n",
        "print(c.min())\n",
        "print(torch.mean(c))\n",
        "print(torch.median(c))\n",
        "print(torch.mode(c))\n",
        "print(torch.std(c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLuIE9MX0LFy",
        "outputId": "dea47de2-cb4a-442b-bff7-6438d92c6062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(24.)\n",
            "tensor(3.)\n",
            "tensor(13.)\n",
            "tensor(12.)\n",
            "torch.return_types.mode(\n",
            "values=tensor([ 8., 12.]),\n",
            "indices=tensor([3, 3]))\n",
            "tensor(6.5683)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Linear Alzebra Operations\n",
        "\n",
        "# PyTorch has a module called torch.linalg that contains a set of built-in linear algebra fucntions that are based on BLAS and LAPACK standardized libraries.\n",
        "\n",
        "# Compute the dot product scalar of two 1d vector\n",
        "first_torch = torch.tensor([1,2,3,9])\n",
        "second_tensor = torch.tensor([11,21,13,91])\n",
        "\n",
        "dot_product = torch.matmul(first_torch, second_tensor)\n",
        "print(dot_product)\n",
        "\n",
        "# Compute the matrix-matrix product (2D tensor) of two 2d tensors\n",
        "first_2d_tensor = torch.tensor([[1,2,3,9],[4,5,6,7]])\n",
        "second_2d_tensor = torch.tensor([[11,21,13,91],[14,51,61,71],[141,511,611,711],[114,151,161,171]])\n",
        "\n",
        "result_2d_tensor = torch.matmul(first_2d_tensor, second_2d_tensor)\n",
        "print(result_2d_tensor)\n",
        "\n",
        "# Compute the a matrix product of 5 2d tensors\n",
        "first_ten = torch.rand(2, 3)\n",
        "second_ten = torch.rand(3, 5)\n",
        "third_ten = torch.rand(5, 7)\n",
        "fourth_ten = torch.rand(7, 11)\n",
        "fifth_ten = torch.rand(11, 2)\n",
        "torch.linalg.multi_dot((first_ten, second_ten, third_ten, fourth_ten, fifth_ten))\n",
        "\n",
        "# Computing eigenvalues and eigenvectors\n",
        "\n",
        "# create a 3x3 square matrix\n",
        "A = torch.randn(4,4)\n",
        "\n",
        "# print the above created matrix\n",
        "print(\"matrix: \", A)\n",
        "\n",
        "# compute the Eigen values and vectors of the matrix\n",
        "eigenvalues, eigenvectors = torch.linalg.eigh(A)\n",
        "\n",
        "# print the Eigen values and vectors\n",
        "print(\"Eigen values: \", eigenvalues)\n",
        "print(\"Eigen vectors: \", eigenvectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlVQZgTo2lB4",
        "outputId": "4ebf2167-186a-402a-cd1d-b810709db595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(911)\n",
            "tensor([[1488, 3015, 3417, 3905],\n",
            "        [1758, 4462, 5150, 6182]])\n",
            "matrix:  tensor([[ 1.2076,  1.3125,  1.4406, -1.6771],\n",
            "        [-0.0088, -0.1027, -1.0516, -0.4410],\n",
            "        [ 0.4180,  0.0018,  0.7646, -0.4020],\n",
            "        [ 0.0268, -1.0073, -0.2743,  0.3182]])\n",
            "Eigen values:  tensor([-0.9402,  0.4711,  1.1695,  1.4873])\n",
            "Eigen vectors:  tensor([[-0.0258, -0.4770,  0.3840,  0.7902],\n",
            "        [ 0.7640, -0.2608, -0.5720,  0.1454],\n",
            "        [ 0.1078,  0.8251, -0.0932,  0.5468],\n",
            "        [ 0.6356,  0.1542,  0.7188, -0.2355]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Automatic Differentiation\n",
        "\n",
        "# A set of techniques that allow us to compute gradients for arbitrary complex loss functions efficiently\n",
        "\n",
        "# After we find the loss function, we calculate the derivative of the loss functiuon in terms of the parameters\n",
        "\n",
        "# We iteratively update the weight parameters accordingly so that the loss function return the smallest possible loss\n",
        "\n",
        "# This step is called iteratively optimization, as we use an optimizer to perform the update of parameters\n",
        "\n",
        "# Two Steps in Training neutral network\n",
        "\n",
        "# Forward propagation\n",
        "\n",
        "# Backward propagation\n",
        "\n",
        "# Every Complex function can be expressed as a composition of elementary functions\n",
        "\n",
        "# For those elementary functions, we could apply symbolic diffrentaition, which would mean storing and manipulating symbolic forms of derivatives\n",
        "\n",
        "# By using automatic diffrenetiation, we don't have to go through the process of simplifying the expressions\n",
        "\n",
        "# Benefits of AD:\n",
        "\n",
        "# instead, evaluate a given set of values\n",
        "\n",
        "# Another benefits of automatic diffrentiation is that our function can contain if-else statements, for loops, or recursion\n",
        "\n",
        "# Funcions f( x,y,z ) =  (x-y)*z\n",
        "\n",
        "# Varibles x,y and z are; x=2, y=1 and z=5\n",
        "\n",
        "# Label an intermediate variable a=x-y\n",
        "\n",
        "# Find gradients off with regard to input variables: df/dx, df/dy, df/dz\n",
        "\n",
        "# Calculate gradients of the loss function with respect to the weights by using chain rule\n"
      ],
      "metadata": {
        "id": "CP_HjOXoG8Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define tensors\n",
        "\n",
        "x = torch.autograd.Variable(torch.tensor([2.0]), requires_grad=True)\n",
        "y = torch.autograd.Variable(torch.tensor([1.0]), requires_grad=True)\n",
        "z = torch.autograd.Variable(torch.tensor([5.0]), requires_grad=True)"
      ],
      "metadata": {
        "id": "34ARYk0uaJAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compute gradients\n",
        "\n",
        "# compute a\n",
        "a = x - y\n",
        "\n",
        "# define the function f\n",
        "f = z - a\n",
        "\n",
        "print(\"final value for function f= \", f)\n",
        "\n",
        "#compute gradients\n",
        "\n",
        "f.backward()\n",
        "\n",
        "print(\"gradient of x= \", x.grad)\n",
        "print(\"gradient of y= \", y.grad)\n",
        "print(\"gradient of z= \", z.grad)"
      ],
      "metadata": {
        "id": "TjXQ3OVfat43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Numerical Differentiation\n",
        "\n",
        "# Follow the definition of derivative\n",
        "\n",
        "# A derivative of y with respect to x defines the rate of change of y with respect to x\n",
        "\n",
        "# dy/dx = ( f( x-dx) - f(x) ) / dx\n",
        "\n",
        "# Cons of numerical Differnetiation\n",
        "\n",
        "# The computational cost, which increases as we increase the number of parameters in the loss functions\n",
        "\n",
        "# The truncation errors\n",
        "\n",
        "# The round-off errors\n",
        "\n"
      ],
      "metadata": {
        "id": "5YQ2g01NK98h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Symbolic Differentiation\n",
        "\n",
        "# Used in Calculus\n",
        "\n",
        "# Using a set or rules, meaning a set of formulas that we can apply to the loss functions to get the gradients\n",
        "\n",
        "# The derivative of a functions f(x) = 3x^2 - 4x + 5\n",
        "\n",
        "# When we apply the symbolic rules, we gw f(x) = 6x - 4\n",
        "\n",
        "# cons\n",
        "\n",
        "# is limited to the already defined symbolic diffrentiation rules\n",
        "\n",
        "# It cannot be used for diffrentiating a given computational procedure\n",
        "\n",
        "# The Computational costs, as it can lead to an explosion of symbolic terms"
      ],
      "metadata": {
        "id": "pJphP5SpOPTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction to the DL Training Process**\n",
        "\n",
        "**Way to build Deep learing model**\n",
        "*   Supervised learning\n",
        "*   Unsuperviced learning\n",
        "*   semi-superviced learning\n",
        "\n",
        "Data preparations ( Generic data, tensors ) -> ML -> outputs\n",
        "\n",
        "**Model Development Stage**\n",
        "\n",
        "*   Take the dataset and split it into three datasets: training data, validation data and testing data\n",
        "*   When we design the model, we use training data to train its parameters\n",
        "\n",
        "**Testing Step**\n",
        "\n",
        "*   Perform backpropagation\n",
        "*   Validate the model by passing in validation data\n",
        "*   Measure model's performance against unseen data\n",
        "*   Tune in hyperparameters\n",
        "*   Common problem is deep learing is overfitting\n",
        "*   Model becomes really good at recognizing what it has been trained on but cannot recognized examples it hasn't seen\n",
        "*   To prevent that, we use a validation ser\n",
        "*   Validation is a crucial step in measuring your model's performance\n",
        "*   DUring this process, you can evaluate training data against validation data that was never used\n",
        "\n",
        "**Model Deployment**\n",
        "\n",
        "*   Save the model to the file\n",
        "*   Or deploy the model to a product or service\n",
        "*   The model is usually deployed to a production environment on a cloud server or to an edge device.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7j-r0UuSew6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data preparation**\n",
        "\n",
        "*   The first step in developing a deep learning model\n",
        "*   Consists of loading the data, applying transforms, and batching the data using pytorch's built-in capabilities.\n",
        "*   Use as exising popular academic dataset called CIFAR-10\n",
        "\n",
        "CIFAR-10\n",
        "\n",
        "\n",
        "*   Developed by researchers from the canadian institute for advanced research, or CIFAR\n",
        "*   Consists of 60,00 small color photographs of objects from 10 classes\n",
        "*   Divided into 50,000 training images and 10,000 test images.\n",
        "*   Use python library called Torchvision; it has classes that support computer vision\n",
        "*   torchvision.datasets module provided several subclasses to load image data from standard datasets such as our CIFAR-10 dataset\n",
        "*   To create a training dataset using the existing CIFAR-10 dataset, we'll import the torch and then import the CIFAR-10 dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZFegam_8h4jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data loading\n",
        "\n",
        "# import libraries and dataset\n",
        "\n",
        "import torch\n",
        "from torchvision.datasets import CIFAR10\n",
        "from keras.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_data = CIFAR10(root='./train/', train=True, download=True, transform=ToTensor())\n",
        "# test_data = CIFAR10(root='./test/', train=False, download=True, transform=ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "AKE5U58qeuj1",
        "outputId": "7937ae4b-20a3-4f38-e593-29b317ed6061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'CIFAR10' from 'keras.datasets' (/usr/local/lib/python3.11/dist-packages/keras/api/datasets/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6e0167805ded>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCIFAR10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCIFAR10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'CIFAR10' from 'keras.datasets' (/usr/local/lib/python3.11/dist-packages/keras/api/datasets/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dataset\n",
        "(trainX, trainy), (testX, testY) = CIFAR10.load_data()\n",
        "\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testY.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "1kFQujLbk0Ap",
        "outputId": "2e1565f5-4840-4cf3-ef5f-a94d3ac1b006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "type object 'CIFAR10' has no attribute 'load_data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-69933946bee5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIFAR10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# summarize loaded dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train: X=%s, y=%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'CIFAR10' has no attribute 'load_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display Images\n",
        "\n",
        "# plot first sixteen images\n",
        "for i in range(0, 16):\n",
        "\t# define subplot\n",
        "\tplt.subplot(4, 4, i+1)\n",
        "\t# plot raw pixel data\n",
        "\tplt.imshow(trainX[i])\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "0pfTOEDqlQ0b",
        "outputId": "39fd73f8-09bd-4235-c434-75e8026000c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a98596019660>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# define subplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# plot raw pixel data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Examine the training dataset\n",
        "\n",
        "print(train_data.data.shape)\n",
        "print(train_data.targets.shape)\n",
        "print(train_data.class_to_idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "82Umwz6NlkBa",
        "outputId": "3c1d8604-f91e-48e0-b521-429b59e9047f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-28f9103be5e8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Examine the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check the class labels\n",
        "for i in range(len(train_data.classes)):\n",
        "  print(i, train_data.classes[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "ULgaqlZCmDCw",
        "outputId": "a59e36a8-7b0d-4e74-d4b5-567d55d1e8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2bed094b345e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@title Check the class labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Transforms"
      ],
      "metadata": {
        "cellView": "form",
        "id": "72mExYXKmWND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import and transform for training data set\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "train_data_path = \"./train/\"\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010]\n",
        "    )])\n",
        "train_data = CIFAR10(root=train_data_path, train=True,\n",
        "                      download=True, transform=train_transforms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSLuUYkEmbt3",
        "outputId": "84e8603c-8295-4df3-952c-c3b111487f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./train/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170M/170M [00:27<00:00, 6.19MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./train/cifar-10-python.tar.gz to ./train/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training data of first image\n",
        "\n",
        "print(train_data[0])\n"
      ],
      "metadata": {
        "id": "COuyQSXBneIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Defining transform for testing data set\n",
        "test_data_path = \"./test/\"\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.20])\n",
        "])\n",
        "\n",
        "test_data = CIFAR10(root=test_data_path, train=False,\n",
        "                        download=True, transform=test_transforms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-U_1IKcnjPT",
        "outputId": "dda0c07b-1556-49c4-ebc2-26167a5c6027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./test/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170M/170M [00:06<00:00, 27.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./test/cifar-10-python.tar.gz to ./test/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Batching**\n",
        "\n",
        "*   A Data loader feeds data from the dataset into the neural network\n",
        "*   At the core of pytorch data loading utility is the torch.utils.data.DataLoader class\n",
        "\n",
        "**Data Loadder Class**\n",
        "Represents a python iterable over a dataset, with support for:\n",
        "\n",
        "*   Map-style and iterable-style datasets\n",
        "*   Customizing data loading order\n",
        "*   Automatic batching\n",
        "*   Single and multi-process data loading\n",
        "\n",
        "1.   The Neural network trains best with batches of data\n",
        "2.   Instead of using the complete datasets in one training pass, we use mini batches, usually 64 or 128 samples.\n",
        "3.   Smaller batches require less memory than the entire dataset, resulting in more efficient and accelerated traing\n",
        "4.   dataloader has, by default, a batch_size of 1\n",
        "5.   batch_size represents a number of images that go through the network before we train and update it\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qZUtCdW7odK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "119UjvJJodFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data batching\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "train_data_path = \"./train/\"\n",
        "test_data_path = \"./test/\"\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010])])\n",
        "training_data = CIFAR10(train_data_path, train=True, download=True, transform=train_transforms)\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010])])\n",
        "test_data = CIFAR10(test_data_path, train=False, download=True, transform=test_transforms)\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=16, shuffle=True)\n",
        "test_data_loader = DataLoader(test_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grMnBU9woTUL",
        "outputId": "644c0a55-140b-4da8-c42d-db4662629ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model development and training\n",
        "\n",
        "# import libraries and dataset\n",
        "import torch\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "# from keras.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define neural network, init and forward functions\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# instantiate the model\n",
        "net = Net()\n",
        "\n",
        "# define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "# load and transfrom the data\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Train the network\n",
        "\n",
        "for epoch in range(10): #loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameters gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfazaOxrsU9a",
        "outputId": "feb750f8-1137-4d31-e4a6-6f497644490d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170M/170M [00:04<00:00, 38.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "[1,  2000] loss: 2.191\n",
            "[1,  4000] loss: 1.867\n",
            "[1,  6000] loss: 1.685\n",
            "[1,  8000] loss: 1.574\n",
            "[1, 10000] loss: 1.535\n",
            "[1, 12000] loss: 1.464\n",
            "[2,  2000] loss: 1.393\n",
            "[2,  4000] loss: 1.367\n",
            "[2,  6000] loss: 1.355\n",
            "[2,  8000] loss: 1.312\n",
            "[2, 10000] loss: 1.302\n",
            "[2, 12000] loss: 1.285\n",
            "[3,  2000] loss: 1.227\n",
            "[3,  4000] loss: 1.209\n",
            "[3,  6000] loss: 1.187\n",
            "[3,  8000] loss: 1.201\n",
            "[3, 10000] loss: 1.193\n",
            "[3, 12000] loss: 1.176\n",
            "[4,  2000] loss: 1.110\n",
            "[4,  4000] loss: 1.112\n",
            "[4,  6000] loss: 1.120\n",
            "[4,  8000] loss: 1.120\n",
            "[4, 10000] loss: 1.103\n",
            "[4, 12000] loss: 1.098\n",
            "[5,  2000] loss: 1.040\n",
            "[5,  4000] loss: 1.053\n",
            "[5,  6000] loss: 1.043\n",
            "[5,  8000] loss: 1.044\n",
            "[5, 10000] loss: 1.047\n",
            "[5, 12000] loss: 1.044\n",
            "[6,  2000] loss: 0.964\n",
            "[6,  4000] loss: 0.987\n",
            "[6,  6000] loss: 0.980\n",
            "[6,  8000] loss: 1.031\n",
            "[6, 10000] loss: 1.003\n",
            "[6, 12000] loss: 1.004\n",
            "[7,  2000] loss: 0.895\n",
            "[7,  4000] loss: 0.948\n",
            "[7,  6000] loss: 0.945\n",
            "[7,  8000] loss: 0.944\n",
            "[7, 10000] loss: 0.978\n",
            "[7, 12000] loss: 0.985\n",
            "[8,  2000] loss: 0.872\n",
            "[8,  4000] loss: 0.900\n",
            "[8,  6000] loss: 0.905\n",
            "[8,  8000] loss: 0.930\n",
            "[8, 10000] loss: 0.893\n",
            "[8, 12000] loss: 0.949\n",
            "[9,  2000] loss: 0.825\n",
            "[9,  4000] loss: 0.858\n",
            "[9,  6000] loss: 0.881\n",
            "[9,  8000] loss: 0.892\n",
            "[9, 10000] loss: 0.913\n",
            "[9, 12000] loss: 0.915\n",
            "[10,  2000] loss: 0.786\n",
            "[10,  4000] loss: 0.817\n",
            "[10,  6000] loss: 0.850\n",
            "[10,  8000] loss: 0.886\n",
            "[10, 10000] loss: 0.866\n",
            "[10, 12000] loss: 0.885\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Validation and testing\n",
        "\n",
        "# import libraries and dataset\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define neural network, init and forward functions\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# instantiate the model\n",
        "net = Net()\n",
        "\n",
        "# define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# load and transfrom the data\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_transforms = transforms.Compose([ transforms.RandomCrop(32, padding=4), # Changed RandomCorp to RandomCrop\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010])])\n",
        "\n",
        "trainset = CIFAR10(root='./train', train=True,\n",
        "                                        download=True, transform=train_transforms)\n",
        "\n",
        "train_set, value_set = random_split(trainset, [45000, 5000])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True)\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(value_set, batch_size=4,\n",
        "                                          shuffle=True)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testset = CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Set the model for training mode and evaluation mode\n",
        "\n",
        "for epoch in range(10): #loop over the dataset multiple times\n",
        "    net.train() # set modal in training mode\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameters gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    net.eval() # set modal for evaluation mode for validation\n",
        "    validation_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            inputs, labels = data\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            validation_loss += loss.item()\n",
        "            _,prediction = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (prediction == labels).sum().item()\n",
        "        print( f'Epoch {epoch + 1}, Traning Loss { running_loss / len(trainloader)}, Validation Loss {validation_loss / len(valloader)}, Accuracy {100 * correct / total}')\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "id": "LvtgqXVGsiPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c370af-48ed-45b3-acb3-991d94a405ea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./train/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170M/170M [00:06<00:00, 25.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./train/cifar-10-python.tar.gz to ./train\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Traning Loss 1.7661233481168748, Validation Loss 3.991722195339203, Accuracy 28.26\n",
            "Epoch 2, Traning Loss 1.5174107562550903, Validation Loss 3.8430473915576933, Accuracy 33.92\n",
            "Epoch 3, Traning Loss 1.4249129274564982, Validation Loss 4.381662471199036, Accuracy 27.95\n",
            "Epoch 4, Traning Loss 1.3690603186619281, Validation Loss 3.9468659352302553, Accuracy 31.5\n",
            "Epoch 5, Traning Loss 1.3334507009992003, Validation Loss 4.422182792663574, Accuracy 29.94\n",
            "Epoch 6, Traning Loss 1.3008704982116819, Validation Loss 4.336253748822212, Accuracy 25.07\n",
            "Epoch 7, Traning Loss 1.2732537155169248, Validation Loss 4.54695656247139, Accuracy 29.33\n",
            "Epoch 8, Traning Loss 1.2611231256994606, Validation Loss 4.53437417602539, Accuracy 27.07\n",
            "Epoch 9, Traning Loss 1.2399582139212637, Validation Loss 4.477007531476021, Accuracy 29.79\n",
            "Epoch 10, Traning Loss 1.2334189281319827, Validation Loss 4.6532459534049035, Accuracy 28.2\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0XPAtsHJeIkX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}